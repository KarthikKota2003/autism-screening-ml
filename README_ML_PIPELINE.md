# Universal ML Pipeline - Complete Package

## ğŸ“¦ What's Included

### 1. Main Pipeline Script
**File:** `ml_pipeline.py`
- Universal script that works for all 4 datasets
- Implements complete leakage-safe ML pipeline
- 4 scalers Ã— 8 algorithms = 32 experiments per dataset
- Comprehensive hyperparameter tuning
- 8 evaluation metrics per experiment

### 2. Usage Guide
**File:** `PIPELINE_USAGE_GUIDE.md`
- Quick start commands
- Detailed usage instructions
- Troubleshooting guide
- Parallel execution examples

### 3. Implementation Plan
**File:** `ML_PIPELINE_IMPLEMENTATION_PLAN.md`
- Complete architecture overview
- Methodology details
- Expected outcomes

### 4. Dependency Checker
**File:** `check_dependencies.py`
- Verifies all required packages
- Provides installation commands

---

## ğŸš€ Quick Start

### Step 1: Check Dependencies
```bash
python check_dependencies.py
```

### Step 2: Run Pipeline on Toddler Dataset
```bash
python ml_pipeline.py --dataset toddler --input Autism_Toddler_Data_Preprocessed.csv --output_dir results/toddler
```

### Step 3: Run with Overfitting Detection and Mitigation (Optional)
```bash
python ml_pipeline.py --dataset adult --input Autism_Adult_Data_Preprocessed.csv --output_dir results/adult --evaluate_train --apply_mitigation
```

---

## ğŸ“Š Pipeline Architecture

```
Input: Preprocessed CSV
    â†“
Train/Test Split (80/20, stratified)
    â†“
Leakage-Safe Encoding
    â”œâ”€â”€ One-Hot: gender, jaundice, family_asd, relation, ethnicity
    â””â”€â”€ Target: contry_of_res (if present)
    â†“
For Each Scaler (4 total):
    â”œâ”€â”€ Quantile Transformer
    â”œâ”€â”€ Power Transformer
    â”œâ”€â”€ Normalizer
    â””â”€â”€ Max Abs Scaler
        â†“
    SMOTE (training data only)
        â†“
    For Each Model (8 total):
        â”œâ”€â”€ Decision Tree (Grid Search)
        â”œâ”€â”€ KNN (Grid Search)
        â”œâ”€â”€ LDA (Grid Search)
        â”œâ”€â”€ Gaussian NB (Grid Search)
        â”œâ”€â”€ Logistic Regression (Bayesian)
        â”œâ”€â”€ AdaBoost (Bayesian)
        â”œâ”€â”€ Random Forest (Bayesian)
        â””â”€â”€ SVM (Bayesian)
            â†“
        5-Fold CV Hyperparameter Tuning
            â†“
        Train on Balanced Data
            â†“
        Evaluate on Test Data
            â†“
        Calculate 8 Metrics:
            â”œâ”€â”€ Accuracy
            â”œâ”€â”€ ROC-AUC
            â”œâ”€â”€ F1-Score
            â”œâ”€â”€ Precision
            â”œâ”€â”€ Recall
            â”œâ”€â”€ MCC
            â”œâ”€â”€ Kappa
            â””â”€â”€ Log Loss
    â†“
Save Results (CSV + JSON)
```

---

## ğŸ“ˆ Expected Output

### Per Dataset:
- **32 trained models** (4 scalers Ã— 8 algorithms)
- **256 metric values** (32 models Ã— 8 metrics)
- **Results CSV** with all experiments
- **Results JSON** with detailed information
- **Summary** showing best configuration

### Example Output Structure:
```
results/
â””â”€â”€ toddler/
    â”œâ”€â”€ toddler_results.csv
    â””â”€â”€ toddler_results.json
```

---

## â±ï¸ Estimated Runtime

| Dataset | Samples | Estimated Time |
|---------|---------|----------------|
| Toddler | 1,054 | 3-4 hours |
| Adult | 704 | 2-3 hours |
| Child | 292 | 1-2 hours |
| Adolescent | 104 | 0.5-1 hour |

**Note:** Runtime depends on CPU cores and hyperparameter search iterations

---

## ğŸ”‘ Key Features

### âœ… Overfitting Detection & Mitigation
- **Training Metrics:** Use `--evaluate_train` to log training accuracy and detect 100% fit.
- **Automated Mitigation:** Use `--apply_mitigation` to automatically tighten hyperparameter grids (e.g., limit tree depth, regularization) to prevent overfitting.

### âœ… Leakage Prevention
- All transformations fit on **train data only**
- Test data never influences any preprocessing
- SMOTE applied to **train data only**

### âœ… Comprehensive Evaluation
- 8 metrics provide complete performance picture
- ROC-AUC used as primary optimization metric
- Results saved for later analysis

### âœ… Appropriate Tuning
- **Grid Search:** Simple models (DT, KNN, LDA, GNB)
- **Bayesian Optimization:** Moderate/complex models (LR, AB, RF, SVM)
- **5-fold CV:** All tuning methods

### âœ… Reproducibility
- Fixed random seed (42)
- Deterministic splits
- Consistent CV folds

### âœ… Input Validation & Missing Value Handling
- **Mandatory Parameters:** gender, jaundice, family_asd, contry_of_res, used_app_before
- **Optional Parameters:** age, ethnicity, relation (can have missing values)
- **'?' Handling:** Automatically replaced with mode from training data
- **NaN Handling:** Categorical NaN imputed with mode, numerical NaN imputed with median
- **Validation:** Checks for missing mandatory fields before processing

---

## ğŸ”§ Customization

### Modify Hyperparameters
Edit `_get_param_grids()` in `ml_pipeline.py`

### Add/Remove Scalers
Edit `scalers` dictionary in `__init__()`

### Add/Remove Models
Edit `_get_models()` method

### Change CV Folds
Change `cv=5` to desired number in tuning methods

---

## ğŸ“ For Other Agents

### To Run on Different Datasets:

**Adolescent:**
```bash
python ml_pipeline.py --dataset adolescent --input Autism_Adolescent_Data_Preprocessed.csv --output_dir results/adolescent
```

**Adult:**
```bash
python ml_pipeline.py --dataset adult --input Autism_Adult_Data_Preprocessed.csv --output_dir results/adult
```

**Child:**
```bash
python ml_pipeline.py --dataset child --input Autism_Child_Data_Preprocessed.csv --output_dir results/child
```

### Parallel Execution
Each agent can run their assigned dataset simultaneously in separate terminals/processes.

---

## ğŸ“š Documentation Files

1. **PIPELINE_USAGE_GUIDE.md** - Detailed usage instructions
2. **ML_PIPELINE_IMPLEMENTATION_PLAN.md** - Architecture and methodology
3. **ENCODING_AND_SCALING_EXPLAINED.md** - Preprocessing details
4. **ENCODING_STRATEGY_ANALYSIS.md** - Encoding rationale
5. **DATASET_ANALYSIS_REPORT.md** - Initial data analysis
6. **CATEGORICAL_COLUMNS_ANALYSIS.md** - Feature analysis

---

## âœ… Ready to Execute

The pipeline is **fully implemented** and **ready to run** on any of the 4 datasets.

**Awaiting confirmation to execute on Toddler dataset.**
